import asyncio
import random
import re
from datetime import datetime
from typing import Dict, List, Any, Optional

from ..memory.base import Message, MemoryContext
from ..memory.buffer_memory import BufferMemory
from ..config.settings import settings
from ..utils.prompt_loader import PromptLoader
from ..utils.time_utils import TimeUtils

class SimplePipelineState:
    """Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ pipeline Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
    def __init__(self):
        self.user_id: str = ""
        self.messages: List[Dict[str, Any]] = []
        self.meta_time: Optional[datetime] = None
        
        # Pipeline state
        self.normalized_input: str = ""
        self.memory_context: str = ""
        self.day_prompt: str = ""
        self.behavior_prompt: str = ""
        self.final_prompt: str = ""
        self.llm_response: str = ""
        self.processed_response: Dict[str, Any] = {}
        
        # Metadata
        self.day_number: int = 1
        self.current_strategy: str = "caring"
        self.question_count: int = 0
        self.processing_start: datetime = datetime.utcnow()

class SimpleAgathaPipeline:
    """Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ pipeline Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð±ÐµÐ· LangGraph"""
    
    def __init__(self):
        self.prompt_loader = PromptLoader()
        self.time_utils = TimeUtils()
        self.memory_instances: Dict[str, BufferMemory] = {}
        
        # Mock LLM Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        self.llm = None
    
    async def process_chat(self, user_id: str, messages: List[Dict], meta_time: Optional[str] = None) -> Dict[str, Any]:
        """Main entry point for chat processing - Ð£ÐŸÐ ÐžÐ©Ð•ÐÐÐÐ¯ Ð’Ð•Ð Ð¡Ð˜Ð¯"""
        state = SimplePipelineState()
        state.user_id = user_id
        state.messages = messages
        
        if meta_time:
            try:
                state.meta_time = datetime.fromisoformat(meta_time.replace('Z', '+00:00'))
            except:
                state.meta_time = datetime.utcnow()
        else:
            state.meta_time = datetime.utcnow()
        
        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ pipeline Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾
        state = await self._ingest_input(state)
        state = await self._short_memory(state)
        state = await self._day_policy(state)
        state = await self._behavior_policy(state)
        state = await self._compose_prompt(state)
        state = await self._llm_call(state)
        state = await self._postprocess(state)
        state = await self._persist(state)
        
        return state.processed_response
    
    async def _ingest_input(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 1: Normalize input and extract metadata"""
        if not state.messages:
            state.normalized_input = ""
            return state
        
        # Get the last user message
        user_messages = [msg for msg in state.messages if msg.get('role') == 'user']
        if user_messages:
            last_message = user_messages[-1]
            state.normalized_input = last_message.get('content', '').strip()
        
        state.day_number = 1  # Simplified
        return state
    
    async def _short_memory(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 2: Load and process short-term memory"""
        user_id = state.user_id
        
        # Get or create memory instance for user
        if user_id not in self.memory_instances:
            self.memory_instances[user_id] = BufferMemory(user_id)
        
        memory = self.memory_instances[user_id]
        
        # Add current message to memory
        if state.normalized_input:
            message = Message(
                role="user",
                content=state.normalized_input,
                timestamp=state.meta_time or datetime.utcnow()
            )
            context = MemoryContext(
                user_id=user_id,
                day_number=state.day_number
            )
            await memory.add_message(message, context)
        
        # Get memory context
        state.memory_context = await memory.get_context(MemoryContext(
            user_id=user_id,
            day_number=state.day_number
        ))
        
        return state
    
    async def _day_policy(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 3: Apply daily scenario policy"""
        state.day_prompt = await self.prompt_loader.get_day_prompt(state.day_number)
        return state
    
    async def _behavior_policy(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 4: Apply behavioral strategy"""
        strategies = ["caring", "reserved", "mysterious", "playful"]
        state.current_strategy = random.choice(strategies)
        
        state.behavior_prompt = await self.prompt_loader.get_behavior_prompt(state.current_strategy)
        return state
    
    async def _compose_prompt(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 5: Compose final prompt"""
        base_prompt = await self.prompt_loader.get_base_prompt()
        
        # Time context
        time_context = self.time_utils.get_time_context(state.meta_time or datetime.utcnow())
        
        # Compose final prompt
        prompt_parts = [
            base_prompt,
            f"\n--- Ð”Ð•ÐÐ¬ {state.day_number} ---",
            state.day_prompt,
            f"\n--- ÐŸÐžÐ’Ð•Ð”Ð•ÐÐ§Ð•Ð¡ÐšÐÐ¯ Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð¯: {state.current_strategy.upper()} ---",
            state.behavior_prompt,
            f"\n--- Ð’Ð Ð•ÐœÐ¯ ---",
            time_context,
            f"\n--- ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐŸÐÐœÐ¯Ð¢Ð˜ ---",
            state.memory_context,
            f"\n--- Ð¢Ð•ÐšÐ£Ð©Ð•Ð• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð• ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð¯ ---",
            state.normalized_input,
            f"\n--- Ð˜ÐÐ¡Ð¢Ð Ð£ÐšÐ¦Ð˜Ð˜ ÐŸÐž ÐžÐ¢Ð’Ð•Ð¢Ð£ ---",
            f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ð½Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°: {settings.MAX_MESSAGE_LENGTH} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².",
            "Ð Ð°Ð·Ð±ÐµÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° 1-3 Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ‡Ð°ÑÑ‚Ð¸ ÐµÑÐ»Ð¸ Ð¾Ð½ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹.",
            "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð¸ ÐºÐ°Ðº Agatha."
        ]
        
        state.final_prompt = "\n".join(prompt_parts)
        return state
    
    async def _llm_call(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 6: Mock LLM call Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        # Mock response Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        user_input = state.normalized_input
        strategy = state.current_strategy
        day = state.day_number
        
        mock_responses = {
            "caring": f"ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ñ€Ð°Ð´Ð° Ñ‚ÐµÐ±Ñ Ð²Ð¸Ð´ÐµÑ‚ÑŒ ðŸ˜Š Ð¢Ñ‹ Ð½Ð°Ð¿Ð¸ÑÐ°Ð»: '{user_input}'. ÐšÐ°Ðº Ñƒ Ñ‚ÐµÐ±Ñ Ð´ÐµÐ»Ð°? Ð¯ Ñ…Ð¾Ñ‡Ñƒ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ Ñ‚ÐµÐ±Ñ!",
            "mysterious": f"Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾... '{user_input}' ðŸ¤” Ð•ÑÑ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾Ðµ Ð² Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ ÑÐºÐ°Ð·Ð°Ð». Ð§Ñ‚Ð¾ ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð·Ð° ÑÑ‚Ð¸Ð¼Ð¸ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸?",
            "playful": f"ÐžÐ¹-Ð¾Ð¹! '{user_input}' ðŸ˜„ Ð¢Ñ‹ Ñ‚Ð°ÐºÐ¾Ð¹ Ð·Ð°Ð±Ð°Ð²Ð½Ñ‹Ð¹! Ð¥Ð¾Ñ‡ÐµÑˆÑŒ Ð¿Ð¾Ð¸Ð³Ñ€Ð°Ñ‚ÑŒ Ð² ÑÐ»Ð¾Ð²ÐµÑÐ½Ñ‹Ðµ Ð¸Ð³Ñ€Ñ‹?",
            "reserved": f"ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÑŽ. Ð¢Ñ‹ ÑÐºÐ°Ð·Ð°Ð»: '{user_input}'. Ð­Ñ‚Ð¾ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° Ð·Ñ€ÐµÐ½Ð¸Ñ."
        }
        
        base_response = mock_responses.get(strategy, f"ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð”ÐµÐ½ÑŒ {day}, ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ {strategy}. Ð¢Ñ‹ ÑÐºÐ°Ð·Ð°Ð»: '{user_input}'")
        
        state.llm_response = base_response
        return state
    
    async def _postprocess(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 7: Post-process response"""
        response_text = state.llm_response
        
        # Check if response contains a question
        has_question = bool(re.search(r'\?', response_text))
        
        # Split response into parts (simplified)
        parts = self._split_response(response_text)
        
        # Calculate delays between parts
        delays_ms = self._calculate_delays(parts)
        
        state.processed_response = {
            "parts": parts,
            "has_question": has_question,
            "delays_ms": delays_ms
        }
        
        return state
    
    async def _persist(self, state: SimplePipelineState) -> SimplePipelineState:
        """Node 8: Persist conversation"""
        # Add assistant response to memory
        user_id = state.user_id
        memory = self.memory_instances.get(user_id)
        if memory:
            assistant_message = Message(
                role="assistant",
                content=" ".join(state.processed_response["parts"]),
                timestamp=datetime.utcnow(),
                metadata={
                    "strategy": state.current_strategy,
                    "day_number": state.day_number,
                    "has_question": state.processed_response["has_question"]
                }
            )
            context = MemoryContext(
                user_id=user_id,
                day_number=state.day_number
            )
            await memory.add_message(assistant_message, context)
        
        print(f"âœ… Persisted conversation for user {user_id}")
        return state
    
    def _split_response(self, text: str) -> List[str]:
        """Split response into 1-3 logical parts"""
        if len(text) <= settings.MAX_MESSAGE_LENGTH:
            return [text]
        
        # Try to split by sentences
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) <= 3:
            return sentences
        
        # Group sentences into 2-3 parts
        if len(sentences) <= 6:
            mid = len(sentences) // 2
            return [
                ". ".join(sentences[:mid]) + ".",
                ". ".join(sentences[mid:]) + "."
            ]
        else:
            third = len(sentences) // 3
            return [
                ". ".join(sentences[:third]) + ".",
                ". ".join(sentences[third:2*third]) + ".",
                ". ".join(sentences[2*third:]) + "."
            ]
    
    def _calculate_delays(self, parts: List[str]) -> List[int]:
        """Calculate typing delays between parts"""
        delays = [0]  # First part has no delay
        
        for i in range(1, len(parts)):
            # Simulate typing delay based on length
            chars = len(parts[i-1])
            typing_time = chars * 1000 // 50  # 50 chars per second
            delay = min(max(typing_time, 500), 3000)  # Between 0.5-3 seconds
            delays.append(delay)
        
        return delays 