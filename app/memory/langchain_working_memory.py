
import os
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

# LangChain imports
try:
    from langchain.memory import ConversationBufferWindowMemory, ConversationSummaryMemory
    from langchain_community.vectorstores import Chroma
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_core.documents import Document
    from langchain.schema import BaseMessage, HumanMessage, AIMessage
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    LANGCHAIN_AVAILABLE = False
    print(f"‚ö†Ô∏è LangChain –∏–º–ø–æ—Ä—Ç –æ—à–∏–±–∫–∞: {e}")

# –ü—Ä–æ–µ–∫—Ç imports
try:
    from ..config.production_config_manager import get_config
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    print("‚ö†Ô∏è Config manager –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")


class WorkingMemorySystem:
    """
    –†–∞–±–æ—á–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –Ω–∞ LangChain
    - Short-term: ConversationBufferWindowMemory (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π)
    - Long-term: Chroma –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î
    - –≠–º–æ—Ü–∏–∏ –∏ —Ç–µ–º—ã: –∏–∑ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    """
    
    def __init__(self, user_id: str, config_file: str = "enhanced_memory_config"):
        self.user_id = user_id
        self.logger = logging.getLogger(f"{__name__}.{user_id}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML
        self.config = self._load_config(config_file)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.short_memory = None  # ConversationBufferWindowMemory
        self.long_memory = None   # Chroma VectorStore
        self.embeddings = None    # OpenAIEmbeddings
        self.llm = None          # ChatOpenAI –¥–ª—è summarization
        
        if LANGCHAIN_AVAILABLE:
            self._initialize_memory_components()
        else:
            self.logger.error("LangChain –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
        
        self.logger.info(f"WorkingMemorySystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è {user_id}")
    
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞"""
        if CONFIG_AVAILABLE:
            try:
                return get_config(config_file, self.user_id, {})
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        
        # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        return {
            "short_memory": {
                "window_size": 10,  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                "memory_key": "chat_history"
            },
            "long_memory": {
                "persist_directory": "./data/vectordb",
                "collection_name": f"user_{self.user_id}"
            },
            "embeddings": {
                "model": "text-embedding-ada-002",
                "chunk_size": 1000
            },
            "llm": {
                "model": "gpt-4o-mini",
                "temperature": 0.3
            },
            "emotion_markers": {
                "happy": ["—Å–ø–∞—Å–∏–±–æ", "–æ—Ç–ª–∏—á–Ω–æ", "üòä"],
                "sad": ["–≥—Ä—É—Å—Ç–Ω–æ", "üò¢"],
                "confused": ["–Ω–µ –ø–æ–Ω–∏–º–∞—é", "ü§î"]
            },
            "topic_keywords": {
                "—Ä–∞–±–æ—Ç–∞": ["—Ä–∞–±–æ—Ç", "–ø—Ä–æ—Ñ–µ—Å—Å–∏—è"],
                "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": ["–ø—Ä–æ–≥—Ä–∞–º–º", "–∫–æ–¥", "–∫–æ–º–ø—å—é—Ç–µ—Ä"]
            },
            "importance_calculation": {
                "role_weights": {"user": 0.7, "assistant": 0.5},
                "length_weights": {"long_threshold": 200, "long_bonus": 0.1},
                "long_threshold": 0.6  # –ø–æ—Ä–æ–≥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ long memory
            }
        }
    
    def _initialize_memory_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç LangChain –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
        try:
            # 1. Short-term –ø–∞–º—è—Ç—å (ConversationBufferWindowMemory)
            window_size = self.config.get("short_memory", {}).get("window_size", 10)
            memory_key = self.config.get("short_memory", {}).get("memory_key", "chat_history")
            
            self.short_memory = ConversationBufferWindowMemory(
                k=window_size,
                memory_key=memory_key,
                return_messages=True
            )
            self.logger.info(f"Short memory –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (–æ–∫–Ω–æ: {window_size})")
            
            # 2. Embeddings
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                embedding_model = self.config.get("embeddings", {}).get("model", "text-embedding-ada-002")
                self.embeddings = OpenAIEmbeddings(
                    model=embedding_model,
                    openai_api_key=api_key
                )
                self.logger.info(f"Embeddings –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã ({embedding_model})")
                
                # 3. Long-term –ø–∞–º—è—Ç—å (Chroma)
                persist_dir = self.config.get("long_memory", {}).get("persist_directory", "./data/vectordb")
                collection_name = self.config.get("long_memory", {}).get("collection_name", f"user_{self.user_id}")
                
                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                Path(persist_dir).mkdir(parents=True, exist_ok=True)
                
                self.long_memory = Chroma(
                    persist_directory=persist_dir,
                    embedding_function=self.embeddings,
                    collection_name=collection_name
                )
                self.logger.info(f"Long memory –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ ({persist_dir}/{collection_name})")
                
                # 4. LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
                llm_model = self.config.get("llm", {}).get("model", "gpt-4o-mini")
                temperature = self.config.get("llm", {}).get("temperature", 0.3)
                
                self.llm = ChatOpenAI(
                    model=llm_model,
                    temperature=temperature,
                    openai_api_key=api_key
                )
                self.logger.info(f"LLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ({llm_model})")
            else:
                self.logger.warning("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∞")
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LangChain: {e}")
    
    def add_message(self, role: str, content: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Å–∏—Å—Ç–µ–º—É –ø–∞–º—è—Ç–∏
        
        Args:
            role: 'user' –∏–ª–∏ 'assistant'
            content: —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            metadata: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            results = {
                "short_memory": False,
                "long_memory": False,
                "emotion": None,
                "topics": [],
                "importance": 0.0
            }
            
            # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)
            emotion = self._detect_emotion(content)
            results["emotion"] = emotion
            
            # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)
            topics = self._detect_topics(content)
            results["topics"] = topics
            
            # 3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)
            importance = self._calculate_importance(content, role)
            results["importance"] = importance
            
            # 4. –î–æ–±–∞–≤–ª—è–µ–º –≤ short-term –ø–∞–º—è—Ç—å
            if self.short_memory:
                if role == "user":
                    self.short_memory.chat_memory.add_user_message(content)
                else:
                    self.short_memory.chat_memory.add_ai_message(content)
                results["short_memory"] = True
                self.logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ short memory")
            
            # 5. –î–æ–±–∞–≤–ª—è–µ–º –≤ long-term –ø–∞–º—è—Ç—å (–µ—Å–ª–∏ –≤–∞–∂–Ω–æ–µ)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback 0.65, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
            importance_config = self.config.get("importance_calculation", {})
            importance_threshold = importance_config.get("long_threshold", 0.75)
            
            self.logger.debug(f"Importance: {importance:.2f}, threshold: {importance_threshold}, will_save: {importance >= importance_threshold}")
            
            if self.long_memory and importance >= importance_threshold:
                document = Document(
                    page_content=content,
                    metadata={
                        "user_id": self.user_id,
                        "role": role,
                        "timestamp": datetime.now().isoformat(),
                        "emotion": emotion,
                        "topics": topics,
                        "importance": importance,
                        **(metadata or {})
                    }
                )
                
                doc_ids = self.long_memory.add_documents([document])
                results["long_memory"] = True
                self.logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ long memory: {doc_ids}")
            
            return results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            return {"error": str(e)}
    
    def _detect_emotion(self, text: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏—é –∏–∑ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)"""
        try:
            emotion_markers = self.config.get("emotion_markers", {})
            text_lower = text.lower()
            
            for emotion, markers in emotion_markers.items():
                if any(marker in text_lower for marker in markers):
                    return emotion
            
            return None
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–∏: {e}")
            return None
    
    def _detect_topics(self, text: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–º—ã –∏–∑ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)"""
        try:
            topic_keywords = self.config.get("topic_keywords", {})
            text_lower = text.lower()
            topics = []
            
            for topic, keywords in topic_keywords.items():
                if any(keyword in text_lower for keyword in keywords):
                    topics.append(topic)
            
            return topics
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º: {e}")
            return []
    
    def _calculate_importance(self, text: str, role: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∏–∑ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ë–ï–ó –•–ê–†–î–ö–û–î–ê)"""
        try:
            importance_config = self.config.get("importance_calculation", {})
            
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª–∏
            role_weights = importance_config.get("role_weights", {})
            base_importance = role_weights.get(role, 0.5)
            
            # –ë–æ–Ω—É—Å –∑–∞ –¥–ª–∏–Ω—É
            length_config = importance_config.get("length_weights", {})
            long_threshold = length_config.get("long_threshold", 200)
            long_bonus = length_config.get("long_bonus", 0.1)
            
            if len(text) > long_threshold:
                base_importance += long_bonus
            
            return min(1.0, max(0.0, base_importance))
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏: {e}")
            return 0.5
    
    def get_context(self, query: str = None, max_results: int = 5) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        
        Args:
            query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è long-term –ø–∞–º—è—Ç–∏
            max_results: –º–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
            
        Returns:
            Dict —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ short –∏ long –ø–∞–º—è—Ç–∏
        """
        try:
            context = {
                "short_memory": [],
                "long_memory": [],
                "total_messages": 0
            }
            
            # 1. Short-term –ø–∞–º—è—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
            if self.short_memory:
                messages = self.short_memory.chat_memory.messages
                context["short_memory"] = [
                    {
                        "role": "user" if isinstance(msg, HumanMessage) else "assistant",
                        "content": msg.content
                    }
                    for msg in messages
                ]
                context["total_messages"] = len(messages)
            
            # 2. Long-term –ø–∞–º—è—Ç—å (–ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É)
            if self.long_memory and query:
                search_results = self.long_memory.similarity_search(
                    query=query,
                    k=max_results
                )
                
                context["long_memory"] = [
                    {
                        "content": doc.page_content,
                        "metadata": doc.metadata
                    }
                    for doc in search_results
                ]
            
            return context
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return {"error": str(e)}
    
    def clear_memory(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Å—é –ø–∞–º—è—Ç—å"""
        try:
            if self.short_memory:
                self.short_memory.clear()
                self.logger.info("Short memory –æ—á–∏—â–µ–Ω–∞")
            
            if self.long_memory:
                # –£–¥–∞–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
                collection_name = self.config.get("long_memory", {}).get("collection_name", f"user_{self.user_id}")
                try:
                    self.long_memory._client.delete_collection(collection_name)
                    self.logger.info("Long memory –æ—á–∏—â–µ–Ω–∞")
                except:
                    pass  # –ö–æ–ª–ª–µ–∫—Ü–∏—è –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–º—è—Ç–∏"""
        try:
            stats = {
                "user_id": self.user_id,
                "short_memory_available": self.short_memory is not None,
                "long_memory_available": self.long_memory is not None,
                "embeddings_available": self.embeddings is not None,
                "config_loaded": bool(self.config)
            }
            
            if self.short_memory:
                stats["short_memory_messages"] = len(self.short_memory.chat_memory.messages)
            
            if self.long_memory:
                try:
                    collection = self.long_memory._collection
                    stats["long_memory_documents"] = collection.count()
                except:
                    stats["long_memory_documents"] = "unknown"
            
            return stats
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"error": str(e)}


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–±–æ—á–µ–π –ø–∞–º—è—Ç–∏
def create_working_memory(user_id: str, config_file: str = "enhanced_memory_config") -> WorkingMemorySystem:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä —Ä–∞–±–æ—á–µ–π —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏."""
    return WorkingMemorySystem(user_id, config_file)
